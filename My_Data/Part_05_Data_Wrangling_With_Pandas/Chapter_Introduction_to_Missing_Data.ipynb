{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Introduction to Missing Data "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- [Handling Missing Data](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)\n",
            "- [Working with missing data](https://pandas.pydata.org/docs/user_guide/missing_data.html#values-considered-missing)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "import pandas as pd\n",
            "import numpy as np\n",
            "from pathlib import Path"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Missing or duplicate data may exist in a data set for a number of different reasons:\n",
            "- Values are missed during data acquisition process\n",
            "    - Faulty weather sensors during weather analysis\n",
            "    - Incomplete patient information for medical diagnosis etc.\n",
            "- Values deleted accidentally\n",
            "    - Data loss\n",
            "    - Mistakenly deleted due to human error\n",
            "    - Data storage or conversion issues\n",
            "- Sometimes, missing or duplicate data is introduced as we perform cleaning and transformation tasks such as:\n",
            "    - Combining data\n",
            "    - Reindexing data\n",
            "    - Reshaping data\n",
            "\n",
            "**Workflow for treating missing values**\n",
            "1. Convert all missing values to null values.\n",
            "2. Analyze the amount and type of missingness in the data.\n",
            "3. Appropriately delete or impute missing values.\n",
            "4. Evaluate & compare the performance of the treated/imputed dataset."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Trade-Offs in Missing Data Conventions\n",
            "\n",
            "There are a number of schemes that have been developed to indicate the presence of missing data in a table or DataFrame. Generally, they revolve around one of two strategies: using a **mask that globally indicates missing values**, or choosing a **sentinel value that indicates a missing entry**.\n",
            "\n",
            "In the masking approach, the mask might be an entirely separate Boolean array, or it may involve appropriation of one bit in the data representation to locally indicate the null status of a value.\n",
            "\n",
            "In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with -9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with **NaN (Not a Number)**, a special value which is part of the IEEE floating-point specification.\n",
            "\n",
            "None of these approaches is without trade-offs: use of a separate mask array requires allocation of an additional Boolean array, which adds overhead in both storage and computation. **A sentinel value reduces the range of valid values that can be represented, and may require extra (often non-optimized) logic in CPU and GPU arithmetic**. Common special values like NaN are not available for all data types.\n",
            "\n",
            "As in most cases where no universally optimal choice exists, different languages and systems use different conventions. For example, the R language uses reserved bit patterns within each data type as sentinel values indicating missing data, while the SciDB system uses an extra byte attached to every cell which indicates a NA state."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## None: Pythonic missing data\n",
            "\n",
            "The first sentinel value used by Pandas is None, a Python singleton object that is often used for missing data in Python code. Because it is a Python object, None cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type 'object' (i.e., arrays of Python objects):"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "import pandas as pd\n",
            "\n",
            "vals1 = np.array([1, None, 3, 4])\n",
            "vals1"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This dtype=object means that the best common type representation NumPy could infer for the contents of the array is that they are Python objects. While this kind of object array is useful for some purposes, any operations on the data will be done at the Python level, with much more overhead than the typically fast operations seen for arrays with native types:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for dtype in [\"object\", \"int\"]:\n",
            "    print(\"dtype =\", dtype)\n",
            "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
            "    print()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The use of Python objects in an array also means that if you perform aggregations like sum() or min() across an array with a None value, you will generally get an error:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "vals1 = np.array([1, None, 3, 4])\n",
            "try:\n",
            "    vals1.sum()\n",
            "except TypeError as e:\n",
            "    print(e)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This reflects the fact that addition between an integer and None is undefined."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## NaN: Missing numerical data\n",
            "\n",
            "The other missing data representation, NaN (acronym for Not a Number), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "vals2 = np.array([1, np.nan, 3, 4])\n",
            "vals2.dtype"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code. You should be aware that NaN is a bit like a data virus–it infects any other object it touches. Regardless of the operation, the result of arithmetic with NaN will be another NaN:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "1 + np.nan"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "0 * np.nan"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Note that this means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "vals2.sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "vals2.min()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "vals2.max()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "NumPy does provide some special aggregations that will ignore these missing values:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.nansum(vals2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.nanmin(vals2)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.nanmax(vals2)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Keep in mind that NaN is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## NaN and None in Pandas\n",
            "\n",
            "NaN and None both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.Series([1, np.nan, 2, None])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "For types that don't have an available sentinel value, Pandas automatically type-casts when NA values are present. For example, if we set a value in an integer array to np.nan, it will automatically be upcast to a floating-point type to accommodate the NA:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "x = pd.Series(range(2), dtype=int)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "x[0] = None"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "x"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Missing Data in Pandas"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.\n",
            "\n",
            "**pandas uses different sentinel values to represent a missing (also referred to as NA) depending on the data type.**\n",
            "\n",
            "\n",
            "`numpy.nan` for NumPy data types. The disadvantage of using NumPy data types is that the original data type will be coerced to `np.float64` or `object`."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.Series([1, 2], dtype=np.int64).reindex([0, 1, 2])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.Series([True, False], dtype=\"bool\").reindex([0, 1, 2])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "`NaT` for NumPy `np.datetime64`, `np.timedelta64`, and `PeriodDtype`. For typing applications, use api.`types.NaTType`."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.Series([1, 2], dtype=np.dtype(\"timedelta64[ns]\")).reindex([0, 1, 2])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "`NA` for StringDtype. These types will maintain the original data type of the data. For typing applications, use `api.types.NAType`."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.Series([\"a\", \"b\"], dtype=\"string\").reindex([0, 1, 2])"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Equality compaisons between `np.nan`, `NaT`, and `NA` do not act like `None`"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "None == None  # noqa: E711"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "np.nan == np.nan"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.NaT == pd.NaT"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.NA == pd.NA"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "To detect these missing value, use the `isna()` or `notna()` methods. `isna()` or `notna()` will also consider None a missing value."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.isna(pd.Series([1, 2], dtype=np.int64).reindex([0, 1, 2]))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# isna() or notna() will also consider None a missing value.\n",
            "ser = pd.Series([1, None], dtype=object)\n",
            "pd.isna(ser)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## NA semantics"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "> Experimental: the behaviour of NA` can still change without warning."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Starting from pandas 1.0, an experimental NA value (singleton) is available to represent scalar missing values. The goal of `NA` is provide a “missing” indicator that can be used consistently across data types (instead of np.nan, None or pd.NaT depending on the data type).\n",
            "\n",
            "For example, when having missing values in a `Series` with the nullable integer dtype, it will use NA:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "s = pd.Series([1, 2, None], dtype=\"Int64\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "s"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "s[2]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "s[2] is pd.NA"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Currently, pandas does not yet use those data types using NA by default a DataFrame or Series, so you need to specify the dtype explicitly. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Operating on Null Values\n",
            "\n",
            "There are several useful methods for detecting, removing, and replacing null values in Pandas data structures. They are:\n",
            "\n",
            "- `isna()`: Generate a boolean mask indicating missing values\n",
            "- `notna()`: Opposite of isna()\n",
            "- `dropna()`: Return a filtered version of the data\n",
            "- `fillna()`: Return a copy of the data with missing values filled or imputed\n",
            "\n",
            "We will conclude this section with a brief exploration and demonstration of these routines."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Detecting null values\n",
            "\n",
            "Pandas data structures have two useful methods for detecting null data: `isna()` and `notna()`. Either one will return a Boolean mask over the data. For example:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "data = pd.Series([1, np.nan, \"hello\", None])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data.isna()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "As mentioned in Data Indexing and Selection, Boolean masks can be used directly as a Series or DataFrame index:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data[data.notna()]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The `isna()` and `notna()` methods produce similar Boolean results for DataFrames."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Dropping null values\n",
            "\n",
            "In addition to the masking used before, there are the convenience methods, `dropna()` (which removes NA values) and fillna() (which fills in NA values). For a Series, the result is straightforward:\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data.dropna()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "For a DataFrame, there are more options. Consider the following DataFrame:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "df = pd.DataFrame([[1, np.nan, 2], [2, 3, 5], [np.nan, 4, 6]])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We cannot drop single values from a DataFrame; we can only drop full rows or full columns. Depending on the application, you might want one or the other, so dropna() gives a number of options for a DataFrame."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "By default, dropna() will drop all rows in which any null value is present:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.dropna(axis=\"index\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Alternatively, you can drop NA values along a different axis; axis=1 drops all columns containing a null value:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.dropna(axis=\"columns\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "But this drops some good data as well; you might rather be interested in dropping rows or columns with all NA values, or a majority of NA values. This can be specified through the how or thresh parameters, which allow fine control of the number of nulls to allow through.\n",
            "\n",
            "The default is how='any', such that any row or column (depending on the axis keyword) containing a null value will be dropped. You can also specify how='all', which will only drop rows/columns that are all null values:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df[3] = np.nan"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.dropna(axis=\"columns\", how=\"all\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "For finer-grained control, the thresh parameter lets you specify a minimum number of non-null values for the row/column to be kept:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.dropna(axis=\"index\", thresh=3)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Here the first and last row have been dropped, because they contain only two non-null values."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Get percentage of missing values in each column\n",
            "(df.isna().sum(axis=\"index\") / df.shape[0]) * 100"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Remove the columns with more than 50% missing values\n",
            "df = pd.DataFrame([[1, np.nan, 2], [2, np.nan, 5], [np.nan, 4, 6], [7, np.nan, 9], [np.nan, 10, 11], [12, np.nan, 14], [15, np.nan, 17]])\n",
            "df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.dropna(axis=\"columns\", thresh=int(df.shape[0] * 0.5))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Filling null values\n",
            "\n",
            "Sometimes rather than dropping NA values, you'd rather replace them with a valid value. This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values. You could do this in-place using the `isna()` method as a mask, but because it is such a common operation Pandas provides the `fillna()` method, which returns a copy of the array with the null values replaced.\n",
            "\n",
            "Consider the following Series:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "metadata": {},
         "outputs": [],
         "source": [
            "data = pd.Series([1, np.nan, 2, None, 3], index=list(\"abcde\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can fill NA entries with a single value, such as zero:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data.fillna(0)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "We can specify a forward-fill to propagate the previous value forward:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# forward-fill\n",
            "data.ffill()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Or we can specify a back-fill to propagate the next values backward:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# back-fill\n",
            "data.bfill()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "For DataFrames, the options are similar, but we can also specify an axis along which the fills take place:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.ffill(axis=\"columns\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Notice that if a previous value is not available during a forward fill, the NA value remains."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
>>>>>>> ee64128a239a40ee7158dd9320346034d958fb68
   "source": [
            "data = {\"A\": [1, 2, None, 4], \"B\": [None, 2, 3, 4]}\n",
            "df = pd.DataFrame(data)\n",
            "df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Fill with column mean\n",
            "df_filled = df.fillna(df.mean())\n",
            "df_filled"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Fill with median\n",
            "df_filled = df.fillna(df.median())\n",
            "df_filled"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Identifying Hidden Missing Data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_path = Path.cwd().parent / \"data\" / \"wh_2015_special.csv\"\n",
            "happiness2015 = pd.read_csv(data_path)\n",
            "happiness2015.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "happiness2015.isna().sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# some missing values in the \"Region\" column has a dot instead of NaN\n",
            "happiness2015[\"Region\"].unique()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "happiness2015[happiness2015[\"Region\"] == \".\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "happiness2015 = pd.read_csv(data_path, na_values=\".\")\n",
            "happiness2015.isna().sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "happiness2015[happiness2015[\"Region\"].isna()]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "happiness2015 = happiness2015.replace(\"?\", np.nan)\n",
            "happiness2015[happiness2015[\"Region\"].isna()]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Advanced Visualization of Missing Data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "data_path = Path.cwd().parent / \"data\" / \"pima-indians-diabetes_data.csv\"\n",
            "diabetes = pd.read_csv(data_path)\n",
            "diabetes.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "diabetes.info()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "diabetes.describe()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<p>The <code>diabetes</code> DataFrame has 0's in the column <code>BMI</code>. But <code>BMI</code> cannot be 0. It should instead be <code>NaN</code>."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Set the 0 values of column 'BMI' to np.nan\n",
            "diabetes.loc[diabetes[\"BMI\"] == 0, \"BMI\"] = np.nan"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "diabetes.describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Analyzing missingness percentage\n",
            "diabetes_nullity = (diabetes.isna().sum() / diabetes.shape[0]) * 100\n",
            "diabetes_nullity"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<p>You'll use the <code>misssingno</code> package which is built for visualizing missing values."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "[missingno GitHub](https://github.com/ResidentMario/missingno)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import missingno as msno\n",
            "import matplotlib.pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Visualize the missingness summary\n",
            "msno.matrix(diabetes)\n",
            "\n",
            "# Display nullity matrix\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "The msno.matrix nullity matrix is a data-dense display which lets you quickly visually pick out patterns in data completion.\n",
            "\n",
            "The sparkline at right summarizes the general shape of the data completeness and points out the rows with the maximum and minimum nullity in the dataset.\n",
            "\n",
            "Finding correlations between missing data helps you gain a deeper understanding of the type of missing data as well as provides suitable ways in which the missing values can be addressed. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Plot missingness heatmap of diabetes\n",
            "msno.heatmap(diabetes)\n",
            "# Show plot\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Sort diabetes dataframe on 'Serum Insulin'\n",
            "sorted_values = diabetes.sort_values(\"Serum_Insulin\")\n",
            "\n",
            "# Visualize the missingness summary of sorted\n",
            "msno.matrix(sorted_values)\n",
            "\n",
            "# Display nullity matrix\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Drop all rows where 'Glucose' has a missing value\n",
            "diabetes = diabetes.dropna(subset=[\"Glucose\"], how=\"all\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Drop rows where 'BMI' has a missing value\n",
            "diabetes = diabetes.dropna(subset=[\"BMI\"], how=\"all\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Visualize the missingness in the data\n",
            "msno.matrix(diabetes)\n",
            "plt.show()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.1"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}