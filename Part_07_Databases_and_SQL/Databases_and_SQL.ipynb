{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delo s podatkovnimi bazami in SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viri:\n",
    "- [Object Relational Tutorial](https://docs.sqlalchemy.org/en/13/orm/tutorial.html)\n",
    "- [SQLite Tutorial](https://www.sqlitetutorial.net/)\n",
    "- [SQLite Python](https://www.sqlitetutorial.net/sqlite-python/)\n",
    "- [SQLite - Commands](https://www.tutorialspoint.com/sqlite/sqlite_commands.htm)\n",
    "- [Command Line Shell For SQLite](https://sqlite.org/cli.html)\n",
    "- [sqlite3 — DB-API 2.0 interface for SQLite databases](https://docs.python.org/3.7/library/sqlite3.html)\n",
    "-[SQLAlchemy — Python Tutorial](https://towardsdatascience.com/sqlalchemy-python-tutorial-79a577141a91)\n",
    "- [Fastest Way to Load Data Into PostgreSQL Using Python](https://hakibenita.com/fast-load-data-python-postgresql)\n",
    "- [A step-by-step SQLAlchemy tutorial](http://www.rmunn.com/sqlalchemy-tutorial/tutorial-0.1.html)\n",
    "- [How to fix common pitfalls with the Python ORM tool SQLAlchemy](https://opensource.com/article/19/9/common-pitfalls-python)\n",
    "- [The Complete Guide of SQL For Data Scientists\n",
    "](https://towardsdatascience.com/the-complete-guide-of-sql-for-data-scientists-902aaced94e4)\n",
    "- [SQLAlchemy tutorial](http://zetcode.com/db/sqlalchemy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas workflow works well when:\n",
    "- the **data fits in memory** (a few gigabytes but not terabytes)\n",
    "- the **data is relatively static** (doesn't need to be loaded into memory every minute because the data has changed)\n",
    "- only a **single person is accessing** the data (shared access to memory is difficult)\n",
    "- **security isn't important** (security is critical for company scale production situations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation a **database is a much better solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a database?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database is a data representation that lives on disk that can be queried, accessed, and updated without using much memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We primarily interact with a database using a **database management system** or **DBMS** for short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database management system (DBMS) is system software for creating and managing databases. A DBMS makes it possible for end users to create, protect, read, update and delete data in a database. The most prevalent type of data management platform, the DBMS essentially serves as an interface between databases and users or application programs, ensuring that data is consistently organized and remains easily accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/dbms.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a business setting, a lot of data may not be stored in text or Excel files. **SQL-based relational databases (such as SQL Server, PostgreSQL, and MySQL) are in wide use**, and many alternative databases have become quite popular. \n",
    "\n",
    "The choice of database is usually dependent on the:\n",
    "- performance, \n",
    "- data integrity, and \n",
    "- scalability needs of an application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pandas workflow, we spend most of our time thinking about what functions and methods to use, where to store intermediate results in variables, and juggling all of these. To work with data stored in a database, we instead use a language called **SQL (or structured query language)**. In SQL, we express each unique request (whether it be fetching a subset of or editing values in the data) as a single query and then ask the DBMS to run the query and display any results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to fetch a specific subset of the data from a database, we would:\n",
    "- write the SQL query: `SELECT * FROM salaries`\n",
    "- ask the DBMS to run the query and display the results to us\n",
    "\n",
    "Here's what the database workflow looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/database_workflow.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the **data lives on disk**, we can work with datasets that consume multiple terabytes of disk space. Many data science teams in industry have **servers and setups in cloud environments** like Microsoft Azure or Amazon Web Services that let team members work with this scale of data. \n",
    "\n",
    "Robust and popular DBMS tools like Postgres and MySQL include powerful features for:\n",
    "- managing user credentials, \n",
    "- security, and \n",
    "- high data throughput (quickly changing data). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sqlite.org/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite is the most popular database in the world and is lightweight enough that the SQLite DBMS is included as a module in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite vs Other SQL databases (PostgreSQL, MySQL, SQL Server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Database Model**\n",
    "    - SQLite is an Embedded DBMS. This means that it is a Serverless DBMS with the ability to run within your applications. \n",
    "    - Other SQL databases implement a Client-Server Model and requires a Database Server to set up and run over a network.-\n",
    "- **Setup Size**\n",
    "    - SQLite has a smaller size of less than 500KB.\n",
    "    - Other SQL databases are much larger in size. Its setup files are more than 200MB in size. \n",
    "- **Supported Data Types**\n",
    "    - SQLite only supports 5 data types i.e. NULL, BLOB, INTEGER, TEXT, and REAL. \n",
    "    - Other SQL databases have the ability to store nearly any type of data that you may need to store in your database.\n",
    "- **Portability**\n",
    "    - SQLite stores its database in one ordinary disk file in any location within the directory. This makes SQLite one of the most portable Relational Database Management Systems (RDBMS). \n",
    "    - Other SQL databases only become portable when you export the database into a file and then upload it to a Server. This can be a tedious task sometimes. \n",
    "- **Multiple Access**\n",
    "    - SQLite doesn’t perform well when it comes to user management. It also lacks the ability to handle simultaneous access by multiple users. \n",
    "    - Other SQL databases perform very well in managing users. It also has the capacity to support simultaneous access by multiple users.\n",
    "- **Functionality**\n",
    "    - SQLite is a simple DBMS, hence, it comes with basic features that are suitable to users of all types.\n",
    "    - Other SQL databases are a complex DBMS that comes with a wide variety of features.\n",
    "- **Speed**\n",
    "    - SQLite is fast, which can be attributed to the fact that it is a lightweight DBMS with simple operations and minimal design. \n",
    "    - Other SQL databases may not be a suitable DBMS for [running fast read queries](https://stackoverflow.com/questions/29452110/sqlite-faster-than-mysql).\n",
    "- **Security Features**\n",
    "    - SQLite doesn’t come with an Authentication System. \n",
    "    - Other SQL databases come with many security features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Command Line Shell For SQLite](https://sqlite.org/cli.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands in SQLite are called **SQLite dot commands** and exception with these commands is that they **should not be terminated by a semi-colon (;).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with typing a simple sqlite3 command at command prompt which will provide you with SQLite command prompt where you will issue various SQLite commands.\n",
    "- `cd data`\n",
    "- `sqlite3 logs.db`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a **listing of the available dot commands**, you can enter `.help` any time. \n",
    "    - `sqlite>.help`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run `.show` command to see **default setting** for your SQLite command prompt\n",
    "    - `sqlite>.show`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To specify that we want to **return the first 5 rows from weblog**, we need to run the following SQL query:\n",
    "    - `sqlite> SELECT * FROM weblog LIMIT 5;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use the following sequence of dot commands to **format your output**.\n",
    "    - `sqlite>.header on`\n",
    "    - `sqlite>.mode column`\n",
    "    - `sqlite>.timer on`\n",
    "    - `sqlite> SELECT * FROM weblog LIMIT 5;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sqlite3 program provides several convenience commands that are useful for looking at the schema of the database. There is nothing that these commands do that cannot be done by some other means. These commands are provided purely as a shortcut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To see a **list of the tables in the database**, you can enter `.tables`.\n",
    "    - `sqlite>.tables`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `.schema` command shows the **complete schema for the database**, or for a single table if an optional tablename argument is provided:\n",
    "    - `sqlite>.schema`\n",
    "    - `sqlite>.schema weblog`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **database usually consists of multiple, related tables of data**. Each table contains rows and columns, just like a CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/sql_table.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To specify that we want to **return the first 5 rows from weblog**, we need to run the following SQL query:\n",
    "    - `SELECT * FROM weblog LIMIT 5;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this query, we specified:\n",
    "- the columns we wanted using `SELECT *`\n",
    "- the table we wanted to query using `FROM recent_grads`\n",
    "- the number of rows we wanted using `LIMIT 5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Vaja: </b> Write a SQL query that returns the first 15 rows from weblog.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT * FROM weblog LIMIT 15;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While in the SELECT part of the query, we express the specific column we want, in the WHERE part we **express the specific rows we want**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT ip,timestamp FROM weblog\n",
    "WHERE status = 200\n",
    "LIMIT 5;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Vaja: </b> Write a SQL query that returns the logs where the ip is 10.131.2.1. Only return the ip and timestamp columns (in that order) and don't limit the number of rows returned.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT ip,timestamp FROM weblog\n",
    "WHERE ip = \"10.131.2.1\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Vaja: </b> Count the number of rows returned from the previous query. <a href=\"https://www.w3schools.com/sql/sql_count_avg_sum.asp\">Help</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT COUNT(ip) FROM weblog\n",
    "WHERE ip = \"10.131.2.1\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the comparison operators we can use:\n",
    "- Less than: `<`\n",
    "- Less than or equal to: `<=`\n",
    "- Greater than: `>`\n",
    "- Greater than or equal to: `>=`\n",
    "- Equal to: `=`\n",
    "- Not equal to: `!=`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most database systems require that the `SELECT` and `FROM` statements come first, before `WHERE` or any other statements.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use the **AND operator to combine multiple filter criteria**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT * FROM weblog\n",
    "WHERE ip = \"10.131.2.1\" AND timestamp < \"2017-11-29 13:47:00\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we wanted to specify a filter that meets **either of the conditions instead**, we would use the **OR operator**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT * FROM weblog\n",
    "WHERE ip = \"10.131.2.1\" OR status = 304;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can enclose the logic we want to be evaluated together in **parentheses**. This is very similar to how we group mathematical calculations together in a particular order. The parentheses make it explictly clear to the database that we want all of the rows where both of the expressions in the statements evaluate to True:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT * FROM weblog\n",
    "WHERE (ip = \"10.131.2.1\" AND status = 304) OR (method = \"POST\");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can **specify the order** using the `ORDER BY` clause. If we instead want the results ordered by the same column but in descending order, we can add the `DESC` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT * FROM weblog\n",
    "WHERE (ip = \"10.131.2.1\" AND status = 304) OR (method = \"POST\")\n",
    "ORDER BY timestamp DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with the SQLite database using raw Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [sqlite3 Python module](https://docs.python.org/3/library/sqlite3.html): The sqlite3 module provides an SQL interface compliant with the DB-API 2.0 specification described by PEP 249, and requires SQLite 3.7.15 or newer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a CSV file data to a SQL database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you pass the file name as `:memory:` to the connect() function of the sqlite3 module, it will create a new database that resides in the memory (RAM) instead of a database file on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sqlite3 import OperationalError\n",
    "\n",
    "weblogs_db = Path.cwd().parent / \"data\" / \"my-weblogs.db\"\n",
    "\n",
    "# create a connection to a databse\n",
    "con = sqlite3.connect(weblogs_db)\n",
    "\n",
    "# create a new table\n",
    "create_table_query = \"\"\"\n",
    "    CREATE TABLE logs (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            ip VARCHAR(16),\n",
    "            timestamp DATETIME,\n",
    "            status INTEGER,\n",
    "            method VARCHAR(20)\n",
    "    );\"\"\"\n",
    "\n",
    "try:\n",
    "    con.execute(create_table_query)\n",
    "    con.commit()\n",
    "except OperationalError as err:\n",
    "    print(f\"Skippig: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblogs_csv = Path.cwd().parent / \"data\" / \"weblogs_clean.csv\"\n",
    "\n",
    "# Then, insert rows of data:\n",
    "with weblogs_csv.open() as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "    line_count = 0\n",
    "    stmt = \"INSERT INTO logs VALUES(NULL, ?, ?, ?, ?)\"\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f\"Column names are {', '.join(row)}\")\n",
    "            line_count += 1\n",
    "        else:\n",
    "            con.execute(stmt, row)\n",
    "            con.commit()\n",
    "    print(\"DONE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection.\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data in the new database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQLite Python: Querying Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Python SQL drivers return a list of tuples when selecting data from a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(weblogs_db)\n",
    "cursor = con.execute(\"SELECT * FROM logs LIMIT 5;\")\n",
    "rows = cursor.fetchall()\n",
    "print(rows)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to work with large results sets, the Cursor class allows us to control the number of results we want to retrieve at any given time. \n",
    "- To **return a single result** (as a tuple), we use the Cursor method `fetchone()`. \n",
    "- To **return n results**, we use the Cursor method `fetchmany(n)`.\n",
    "\n",
    "Each Cursor instance contains an internal counter that updates every time we retrieve results. When we call the fetchone() method, the Cursor instance will return a single result, and then increment its internal counter by 1. This means that if we call fetchone() again, the Cursor instance will actually return the second tuple in the results set (and increment by 1 again)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako bi se povezali v druge vrste podatkovnih baz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PostgreSQL:\n",
    "    - `psycopg2`: [Psycopg](https://pypi.org/project/psycopg2/) is the most popular PostgreSQL database adapter for the Python programming language.\n",
    "- Microsoft SQL Server:\n",
    "    - `pyodbc`: [pyodbc](https://pypi.org/project/pyodbc/) is an open source Python module that makes accessing ODBC databases simple. It implements the DB API 2.0 specification but is packed with even more Pythonic convenience.\n",
    "- MySQL:\n",
    "    - `PyMySQL`: [PyMySQL](https://pypi.org/project/PyMySQL/) package contains a pure-Python MySQL client library, based on PEP 249."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.sqlalchemy.org/\n",
    "- [ORM Quick Start](https://docs.sqlalchemy.org/en/14/orm/quickstart.html)\n",
    "- [SQLAlchemy 1.4 / 2.0 Tutorial](https://docs.sqlalchemy.org/en/14/tutorial/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLAlchemy is the **Python SQL toolkit** and **Object Relational Mapper** that gives application developers the full power and flexibility of SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It provides a full suite of well known enterprise-level persistence patterns, designed for efficient and high-performing database access, adapted into a simple and Pythonic domain language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLAlchemy is presented as **two distinct APIs**, one building on top of the other. These APIs are known as **Core** and **ORM**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SQLAlchemy Core** is the foundational architecture for SQLAlchemy as a “database toolkit”. The library provides tools for managing connectivity to a database, interacting with database queries and results, and programmatic construction of SQL statements.\n",
    "- **SQLAlchemy ORM** builds upon the Core to provide optional object relational mapping capabilities. The ORM provides an additional configuration layer allowing user-defined Python classes to be mapped to database tables and other constructs, as well as an object persistence mechanism known as the Session. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check to verify that we are on version 1.4 of SQLAlchemy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "sqlalchemy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing Connectivity - the Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The start of any SQLAlchemy application is an object called the Engine.** This object acts as a central source of connections to a particular database, providing both a factory as well as a holding space called a connection pool for these database connections.\n",
    "- The engine is typically a global object **created just once for a particular database server**.\n",
    "- Configured using a **URL string** which will describe how it should connect to the database host or backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Engine is created by using `create_engine()`, specifying the `create_engine.future` flag set to True so that we make full use of 2.0 style usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(weblogs_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# We have also specified a parameter create_engine.echo, which will instruct the Engine to log all\n",
    "# of the SQL it emits to a Python logger that will write to standard out\n",
    "engine = create_engine(f\"sqlite+pysqlite:///{weblogs_db}\", echo=True, future=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main argument to `create_engine` is a string URL: `dialect+driver://username:password@host:port/database`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **What kind of database are we communicating with?** \n",
    "    - Links in SQLAlchemy to an object known as the **dialect**.\n",
    "    - [Engine Configuration](https://docs.sqlalchemy.org/en/14/core/engines.html)\n",
    "    - [Dialects](https://docs.sqlalchemy.org/en/14/dialects/index.html)\n",
    "    - Included Dialects: PostgreSQL, MySQL and MariaDB, SQLite, Oracle, Microsoft SQL Server\n",
    "2. **What DBAPI are we using?** \n",
    "    - The Python DBAPI is a third party driver that SQLAlchemy uses to interact with a particular database. \n",
    "    - In this case, we’re using the name pysqlite, which in modern Python use is the sqlite3 standard library interface for SQLite. \n",
    "    - If omitted, SQLAlchemy will use a default DBAPI for the particular database selected.\n",
    "    - All dialects require that an appropriate DBAPI driver is installed.\n",
    "        - Support for the MySQL database via the PyMySQL driver: `pip install PyMySQL`\n",
    "        - Support for the PostgreSQL database via the psycopg2 driver: `pip install psycopg2`\n",
    "3. **How do we locate the database?** \n",
    "    - URLs typically include username, password, hostname, database name fields, as well as optional keyword arguments for additional configuration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Engine, when first returned by create_engine(), has not actually tried to connect to the database yet; that happens only the first time it is asked to perform a task against the database. This is a software design pattern known as lazy initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Database Urls Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The <a class=\"reference internal\" href=\"#sqlalchemy.create_engine\" title=\"sqlalchemy.create_engine\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">create_engine()</span></code></a> function produces an <a class=\"reference internal\" href=\"connections.html#sqlalchemy.engine.Engine\" title=\"sqlalchemy.engine.Engine\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Engine</span></code></a> object based\n",
    "on a URL.  These URLs follow <a class=\"reference external\" href=\"http://rfc.net/rfc1738.html\">RFC-1738</a>, and usually can include username, password,\n",
    "hostname, database name as well as optional keyword arguments for additional configuration.\n",
    "In some cases a file path is accepted, and in others a “data source name” replaces\n",
    "the “host” and “database” portions.  The typical form of a database URL is:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dialect+driver://username:password@host:port/database`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycopg2 driver\n",
    "engine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/mydatabase\", echo=True, future=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMySQL driver\n",
    "engine = create_engine(\"mysql+pymysql://scott:tiger@localhost/foo\", echo=True, future=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlite://<nohostname>/<path>\n",
    "# where <path> is relative:\n",
    "engine = create_engine(\"sqlite:///data/foo.db\", echo=True, future=True)\n",
    "engine = create_engine(\"sqlite+pysqlite:///:memory:\", echo=True, future=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite connects to file-based databases, using the Python built-in module sqlite3 by default.\n",
    "\n",
    "As SQLite connects to local files, the URL format is slightly different. The “file” portion of the URL is the filename of the database. For a relative file path, this requires three slashes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Transactions and the DBAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`text()`](https://docs.sqlalchemy.org/en/14/core/sqlelement.html#sqlalchemy.sql.expression.text) construct **allows us to write SQL statements as textual SQL**. Rest assured that textual SQL in day-to-day SQLAlchemy use is by far the exception rather than the rule for most tasks, even though it always remains fully available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "print(text(\"SELECT * FROM 'logs' LIMIT 2;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sole purpose of the Engine object from a user-facing perspective is to provide a unit of connectivity to the database called the **Connection**.  \n",
    "- When working with the **Core directly**, the **Connection object is how all interaction with the database is done**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(f\"sqlite+pysqlite:///{weblogs_db}\", echo=True, future=True)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM logs LIMIT 2;\"))\n",
    "    print(type(result))\n",
    "    print(result.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **transaction is not committed automatically**; when we want to commit data we normally need to call `Connection.commit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"CREATE TABLE IF NOT EXISTS some_table (x int, y int)\"))\n",
    "    conn.execute(\n",
    "        text(\"INSERT INTO some_table (x, y) VALUES (:x, :y)\"),\n",
    "        [{\"x\": 1, \"y\": 1}, {\"x\": 2, \"y\": 4}],\n",
    "    )\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want the work we’ve done to be committed within our block, we invoke the `Connection.commit()` method which commits the transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Connection.execute()` method therefore also **accepts parameters**, which are referred towards as bound parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> However, when using textual SQL, a Python literal value, even non-strings like integers or dates, should never be stringified into SQL string directly; a parameter should always be used. This is most famously known as how to **avoid SQL injection attacks when the data is untrusted**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also another style of committing data, which is that we can declare our “connect” block to be a transaction block up front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mode of operation, we use the `Engine.begin()` method to acquire the connection. This method will both manage the scope of the Connection and also enclose everything inside of a transaction with COMMIT at the end, assuming a successful block, or ROLLBACK in case of exception raise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    conn.execute(\n",
    "        text(\"INSERT INTO some_table (x, y) VALUES (:x, :y)\"),\n",
    "        [{\"x\": 6, \"y\": 8}, {\"x\": 9, \"y\": 10}],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“Begin once” style is often preferred** as it is more succinct and indicates the intention of the entire block up front. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetching Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM logs LIMIT 5;\"))\n",
    "    for row in result:\n",
    "        print(f\"IP: {row.ip}  Medhod: {row.method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object returned is called Result and represents an **iterable object of result rows**. The Row objects themselves are intended to act like Python **named tuples**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result has lots of methods for fetching and transforming rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    rs = con.execute(text(\"SELECT * FROM logs LIMIT 5;\"))\n",
    "    data = rs.fetchone()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    rs = conn.execute(text(\"SELECT * FROM logs LIMIT 5;\"))\n",
    "    data1 = rs.fetchone()\n",
    "    data2 = rs.fetchone()\n",
    "    print(data1)\n",
    "    print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    rs = conn.execute(text(\"SELECT * FROM logs LIMIT 5;\"))\n",
    "    data = rs.fetchmany(3)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    rs = conn.execute(text(\"SELECT * FROM logs LIMIT 5;\"))\n",
    "    data = rs.fetchall()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Database Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central element of both SQLAlchemy Core and ORM is the **SQL Expression Language** which allows for fluent, composable construction of SQL queries. \n",
    "- The foundation for these queries are Python objects that represent database concepts like tables and columns -> **database metadata**.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common foundational objects for database metadata in SQLAlchemy are known as `MetaData`, `Table`, and `Column`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start using the SQLAlchemy Expression Language, we will want to have Table objects constructed that represent all of the database tables we are interested in working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a **single MetaData object for an entire application is the most common case**, represented as a module-level variable in a single place in an application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a MetaData object, we can declare some Table objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table\n",
    "\n",
    "user_table = Table(\n",
    "    \"user_account\",\n",
    "    metadata_obj,\n",
    "    Column(\"id\", Integer, primary_key=True),\n",
    "    Column(\"name\", String(30), nullable=False),\n",
    "    Column(\"fullname\", String, nullable=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_table.c.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_table.c.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first useful thing we can do with this structure will be to emit CREATE TABLE statements, or DDL, to our SQLite database so that we can insert and query data from them. We have already all the tools needed to do so, by invoking the MetaData.create_all() method on our MetaData, sending it the Engine that refers to the target database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "user_db = Path.cwd().parent / \"data\" / \"users.db\"\n",
    "\n",
    "engine = create_engine(f\"sqlite+pysqlite:///{user_db}\", echo=True, future=True)\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example of Insert illustrating the target table and the VALUES clause at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "stmt1 = insert(user_table).values(name=\"matic\", fullname=\"matic lalalala\")\n",
    "stmt2 = insert(user_table).values(name=\"jaka\", fullname=\"jaka tatatatat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(stmt1)\n",
    "    conn.execute(stmt2)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The select() construct builds up a statement in the same way as that of insert(), using a generative approach where each method builds more state onto the object. Like the other SQL constructs, it can be stringified in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select(user_table).where(user_table.c.name == \"matic\")\n",
    "print(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with databases and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [SQL queries](https://pandas.pydata.org/docs/user_guide/io.html#sql-queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas.io.sql` module provides a **collection of query wrappers to both facilitate data retrieval** and to reduce dependency on DB-specific API. \n",
    "- Database abstraction is provided by **SQLAlchemy** if installed. \n",
    "- In addition you will need a **driver library for your database**. \n",
    "    - Examples of such drivers are psycopg2 for PostgreSQL or pymysql for MySQL. \n",
    "    - For SQLite this is included in Python’s standard library by default. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"longtable docutils\">\n",
    "<colgroup>\n",
    "<col width=\"10%\">\n",
    "<col width=\"90%\">\n",
    "</colgroup>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-odd\"><td><a class=\"reference internal\" href=\"../reference/api/pandas.read_sql_table.html#pandas.read_sql_table\" title=\"pandas.read_sql_table\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">read_sql_table</span></code></a>(table_name,&nbsp;con[,&nbsp;schema,&nbsp;…])</td>\n",
    "<td>Read SQL database table into a DataFrame.</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><a class=\"reference internal\" href=\"../reference/api/pandas.read_sql_query.html#pandas.read_sql_query\" title=\"pandas.read_sql_query\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">read_sql_query</span></code></a>(sql,&nbsp;con[,&nbsp;index_col,&nbsp;…])</td>\n",
    "<td>Read SQL query into a DataFrame.</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><a class=\"reference internal\" href=\"../reference/api/pandas.read_sql.html#pandas.read_sql\" title=\"pandas.read_sql\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">read_sql</span></code></a>(sql,&nbsp;con[,&nbsp;index_col,&nbsp;…])</td>\n",
    "<td>Read SQL query or database table into a DataFrame.</td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><a class=\"reference internal\" href=\"../reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql\" title=\"pandas.DataFrame.to_sql\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">DataFrame.to_sql</span></code></a>(self,&nbsp;name,&nbsp;con[,&nbsp;schema,&nbsp;…])</td>\n",
    "<td>Write records stored in a DataFrame to a SQL database.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The function `read_sql()` is a convenience wrapper around `read_sql_table()` and `read_sql_query()` (and for backward compatibility) and will delegate to specific function depending on the provided input (database table name or sql query). Table names do not need to be quoted if they have special characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with SQLAlchemy you use the `create_engine()` function to create an engine object from database URI. You only need to create the engine once per database you are connecting to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can use a temporary SQLite database where data are stored in “memory”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a DataFrame to a SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "c = [\"id\", \"Date\", \"Col_1\", \"Col_2\", \"Col_3\"]\n",
    "\n",
    "d = [\n",
    "    (26, datetime.datetime(2010, 10, 18), \"X\", 27.5, True),\n",
    "    (42, datetime.datetime(2010, 10, 19), \"Y\", -12.5, False),\n",
    "    (63, datetime.datetime(2010, 10, 20), \"Z\", 5.73, True),\n",
    "]\n",
    "\n",
    "\n",
    "data = pd.DataFrame(d, columns=c)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql(\"data\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some databases, **writing large DataFrames can result in errors** due to packet size limitations being exceeded. This can be avoided by setting the `chunksize` parameter when calling `to_sql`. For example, the following writes data to the database in batches of 1000 rows at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql(\"data_chunked\", engine, chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a list of tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "print(inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`to_sql()` will **try to map your data to an appropriate SQL data type** based on the dtype of the data. When you have columns of **dtype object, pandas will try to infer the data type**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always override the default type by specifying the desired SQL type of any of the columns by using the dtype argument. This argument needs a dictionary mapping column names to SQLAlchemy types. For example, specifying to use the sqlalchemy String type instead of the default Text type for string columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.types import String\n",
    "\n",
    "data.to_sql(\"data_dtype\", engine, dtype={\"Col_1\": String})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SQLAlchemy, `to_sql()` **is capable of writing datetime data that is timezone naive or timezone aware**. However, the resulting data stored in the database ultimately depends on the supported data type for datetime data of the database system being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if_exists : {‘fail’, ‘replace’, ‘append’}, default ‘fail’**\n",
    "\n",
    "How to behave if the table already exists.\n",
    "- fail: Raise a ValueError.\n",
    "- replace: Drop the table before inserting new values.\n",
    "- append: Insert new values to the existing table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate error\n",
    "data.to_sql(\"data\", engine, if_exists=\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql(\"data\", engine, if_exists=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql(\"data\", engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data from a SQL database table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [read_sql_table](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql_table.html#pandas.read_sql_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_sql_table()` will read a database table given the table name and optionally a subset of columns to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql_table(\"data\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that pandas infers column dtypes from query outputs, and not by looking up data types in the physical database schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the name of the column as the DataFrame index, and specify a subset of columns to be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_table(\"data\", engine, index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can explicitly force columns to be parsed as dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_table(\"data\", engine, parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying a SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **query using raw SQL** in the `read_sql_query()` function. \n",
    "- In this case you must use the SQL variant appropriate for your database. \n",
    "- When using SQLAlchemy, you can also pass SQLAlchemy Expression language constructs, which are database-agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM data\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT id, Col_1, Col_2 FROM data WHERE id = 42;\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_sql_query()` function supports a chunksize argument. Specifying this will return an iterator through chunks of the query result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(20, 3), columns=list(\"abc\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"data_chunks\", engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in pd.read_sql_query(\"SELECT * FROM data_chunks\", engine, chunksize=5):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sqlalchemy.text()` to specify query parameters in a **backend-neutral way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "pd.read_sql_query(sqlalchemy.text(\"SELECT * FROM data where Col_1=:col1\"), engine, params={\"col1\": \"X\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an SQLAlchemy description of your database you can express where conditions using SQLAlchemy expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, MetaData, Table\n",
    "\n",
    "metadata = MetaData()\n",
    "\n",
    "data_table = Table(\n",
    "    \"data\",\n",
    "    metadata,\n",
    "    Column(\"index\", sqlalchemy.Integer),\n",
    "    Column(\"Date\", sqlalchemy.DateTime),\n",
    "    Column(\"Col_1\", sqlalchemy.String),\n",
    "    Column(\"Col_2\", sqlalchemy.Float),\n",
    "    Column(\"Col_3\", sqlalchemy.Boolean),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(sqlalchemy.select(data_table).where(data_table.c.Col_1 == \"X\"), engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Data import from CSV to SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df = pd.read_csv(weblogs_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pretvorbe](https://www.programiz.com/python-programming/datetime/strftime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df[\"Time\"] = pd.to_datetime(weblog_df[\"Time\"], format=\"%d/%b/%Y:%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df.rename(columns={\"IP\": \"ip\", \"Time\": \"timestamp\", \"Staus\": \"status\", \"Method\": \"method\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodamo HTTP_Ok če je Status enak 200\n",
    "weblog_df[\"http_ok\"] = weblog_df[\"status\"] == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Boolean, DateTime, Integer, String, create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblogs_db = Path.cwd().parent / \"data\" / \"web_logs.db\"\n",
    "engine = create_engine(f\"sqlite:///{weblogs_db}\", echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {\"ip\": String(15), \"timestamp\": DateTime(), \"status\": Integer(), \"method\": String(10), \"http_ok\": Boolean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog_df.to_sql(name=\"weblog\", con=engine, if_exists=\"append\", index=False, chunksize=100, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog = pd.read_sql_table(\"weblog\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblog.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_table(\"weblog\", engine, columns=[\"ip\", \"timestamp\", \"method\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Vaja: </b> Write a SQL query that returns a df with all columns for ip = '10.128.2.1' using method GET. Use sqlalchemy.text() to specify query parameters in a backend-neutral way.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(sqlalchemy.text(\"SELECT * FROM weblog WHERE ip=:ip_val AND method=:method_val;\"), engine, params={\"ip_val\": \"10.128.2.1\", \"method_val\": \"GET\"}).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SQLAlchemy expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "\n",
    "weblog_table = Table(\n",
    "    \"weblog\",\n",
    "    metadata,\n",
    "    Column(\"ip\", sqlalchemy.String),\n",
    "    Column(\"timestamp\", sqlalchemy.DateTime),\n",
    "    Column(\"status\", sqlalchemy.Integer),\n",
    "    Column(\"method\", sqlalchemy.String),\n",
    "    Column(\"http_ok\", sqlalchemy.Boolean),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(sqlalchemy.select(weblog_table).where((weblog_table.c.ip == \"10.128.2.1\") & (weblog_table.c.method == \"GET\")), engine).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
